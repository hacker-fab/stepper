{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ineffective!\n",
    "\n",
    "def detect_fiducials(image_path):\n",
    "    # 1. Read and convert to grayscale\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Threshold to isolate bright regions (tune 'thresh_value' if needed)\n",
    "    thresh_value = 200\n",
    "    _, thresh = cv2.threshold(gray, thresh_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 3. Morphological cleanup to remove small specks and fill gaps\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # 4. Find contours\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Keep track of potential cross centers\n",
    "    cross_centers = []\n",
    "\n",
    "    # 5. Filter and visualize\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        # Skip contours that are too small or too large to be crosses\n",
    "        if area < 50 or area > 20000:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = float(w)/float(h)\n",
    "        \n",
    "        # A simple heuristic: crosses are often roughly square in their bounding box\n",
    "        if 0.8 < aspect_ratio < 1.2:\n",
    "            # Compute center for alignment or further processing\n",
    "            cx, cy = x + w//2, y + h//2\n",
    "            cross_centers.append((cx, cy))\n",
    "\n",
    "            # Draw a rectangle around the contour on the original image\n",
    "            print(f\"detected: {(x, y)}\")\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # 6. Show results side by side\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Thresholded Image')\n",
    "    plt.imshow(thresh, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Detected Fiducials')\n",
    "    # Convert from BGR to RGB for correct color display with matplotlib\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return cross_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(locations, radius=10):\n",
    "    \"\"\"\n",
    "    Given a list of (x, y, match_score) tuples and a suppression radius,\n",
    "    return a filtered list so that no two points are closer than 'radius'.\n",
    "    \"\"\"\n",
    "    if not locations:\n",
    "        return []\n",
    "\n",
    "    # Sort by score descending so we keep strongest matches first\n",
    "    locations = sorted(locations, key=lambda x: x[2], reverse=True)\n",
    "    kept = []\n",
    "\n",
    "    for (x, y, score) in locations:\n",
    "        too_close = False\n",
    "        for (kx, ky, kscore) in kept:\n",
    "            # Euclidean distance check\n",
    "            if (x - kx)**2 + (y - ky)**2 < radius**2:\n",
    "                too_close = True\n",
    "                break\n",
    "        if not too_close:\n",
    "            kept.append((x, y, score))\n",
    "\n",
    "    return kept\n",
    "\n",
    "def detect_crosses_via_template(chip_path, template_path, match_thresh=0.8):\n",
    "    \"\"\"\n",
    "    Detect plus-shaped fiducials in 'chip_path' image by matching\n",
    "    a known 'template_path' plus shape.\n",
    "    \"\"\"\n",
    "    # 1. Read images (grayscale)\n",
    "    chip_img = cv2.imread(chip_path, cv2.IMREAD_GRAYSCALE)\n",
    "    template_img = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check that they loaded\n",
    "    if chip_img is None or template_img is None:\n",
    "        raise IOError(\"Could not read chip or template image!\")\n",
    "\n",
    "    # 2. Optionally threshold or preprocess if desired\n",
    "    #    (Sometimes it helps to invert the template or the main image.)\n",
    "    # For demonstration, let's do a slight blur on the chip image\n",
    "    chip_blur = cv2.GaussianBlur(chip_img, (3, 3), 0)\n",
    "\n",
    "    # 3. MatchTemplate\n",
    "    # TM_CCOEFF_NORMED or TM_CCORR_NORMED are commonly used methods.\n",
    "    res = cv2.matchTemplate(chip_blur, template_img, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "    # 4. Threshold the match score\n",
    "    # This creates a mask for all points above match_thresh\n",
    "    match_mask = (res >= match_thresh)\n",
    "    ys, xs = np.where(match_mask)\n",
    "\n",
    "    # Collect matches with their correlation score\n",
    "    # We store the *center* of the matched region\n",
    "    h_t, w_t = template_img.shape[:2]\n",
    "    match_points = []\n",
    "    for (x, y) in zip(xs, ys):\n",
    "        score = res[y, x]\n",
    "        center_x = x + w_t // 2\n",
    "        center_y = y + h_t // 2\n",
    "        match_points.append((center_x, center_y, score))\n",
    "\n",
    "    # 5. Non-maximum suppression to reduce duplicates\n",
    "    filtered = non_max_suppression(match_points, radius=10)\n",
    "\n",
    "    # 6. Visualize results\n",
    "    # Convert to color for drawing\n",
    "    chip_color = cv2.cvtColor(chip_img, cv2.COLOR_GRAY2BGR)\n",
    "    for (cx, cy, sc) in filtered:\n",
    "        print(f\"detected: {cx, cy}\")\n",
    "        cv2.drawMarker(\n",
    "            chip_color, (cx, cy), (0, 0, 255),\n",
    "            markerType=cv2.MARKER_CROSS, markerSize=20, thickness=2\n",
    "        )\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Template Image\")\n",
    "    plt.imshow(template_img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Detected Crosses (red markers)\")\n",
    "    plt.imshow(chip_color[..., ::-1])  # BGR to RGB\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print or return the final coordinates\n",
    "    final_coords = [(int(cx), int(cy)) for (cx, cy, sc) in filtered]\n",
    "    return final_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_crosses_skeleton(image_path):\n",
    "    # 1) Read & Threshold\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Adjust threshold as needed\n",
    "    _, bw = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 2) Morphological open/close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "    bw = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # 3) Skeletonize (skimage wants bool or 0/1)\n",
    "    bw_bool = (bw > 0).astype(np.uint8)\n",
    "    skeleton = skeletonize(bw_bool).astype(np.uint8)\n",
    "\n",
    "    # 4) Identify cross candidates\n",
    "    # We'll look for \"branch points\" in the skeleton. A branch point\n",
    "    # is a pixel with 3+ neighbors that are also skeleton pixels.\n",
    "    # For a perfect cross, we want exactly 4 neighbors.\n",
    "    crosses = []\n",
    "    height, width = skeleton.shape\n",
    "    for y in range(1, height-1):\n",
    "        for x in range(1, width-1):\n",
    "            if skeleton[y, x] == 1:\n",
    "                # Count how many 8-connected neighbors are also 1\n",
    "                # (You might do 4-connected if your cross is purely orth.)\n",
    "                neighbors = 0\n",
    "                coords = []\n",
    "                for ny in range(y-1, y+2):\n",
    "                    for nx in range(x-1, x+2):\n",
    "                        if (ny, nx) != (y, x) and skeleton[ny, nx] == 1:\n",
    "                            neighbors += 1\n",
    "                            coords.append((nx, ny))\n",
    "\n",
    "                # If we want exactly 4 arms in an orthogonal cross,\n",
    "                # we might prefer 4-connected neighbors. \n",
    "                # But let's proceed with 8-connected logic to find \"branch points.\"\n",
    "                if neighbors == 4:\n",
    "                    # We found a candidate center of a cross. \n",
    "                    # Optionally check orientation of each neighbor\n",
    "                    # or measure arm lengths in each direction, etc.\n",
    "                    crosses.append((x, y))\n",
    "\n",
    "    # We'll mark these in the color image\n",
    "    for (cx, cy) in crosses:\n",
    "        print(f\"detected: {cx, cy}\")\n",
    "        cv2.drawMarker(img_bgr, (cx, cy), (0,0,255), markerType=cv2.MARKER_CROSS, markerSize=15, thickness=2)\n",
    "\n",
    "    # Show\n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "    axes[0].imshow(skeleton, cmap='gray')\n",
    "    axes[0].set_title(\"Skeleton\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(\"Detected Cross Centers\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return crosses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"litho_captures/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stepper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
